{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e60bcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46259,
     "status": "ok",
     "timestamp": 1747919604358,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "08e60bcb",
    "outputId": "956994d3-a47d-4972-f373-3b8462d9955f"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "# problema librerie che usano OpenMP, due versioni di OpenMP sono caricate nello stesso processo, ad esempio da PyTorch e da NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d53e47a",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1747919610825,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "8d53e47a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/DAML/DAML_project/data_images\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(os.getcwd(), \"DAML_project\", 'data_images')\n",
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e1097c",
   "metadata": {
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1747919615523,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "b4e1097c"
   },
   "outputs": [],
   "source": [
    "# Mean e std per immagini RGB normalizzate su [-1, 1]\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# per fare data augmentation utiliziammo transforms.Compose di torchvision, facciamo data augmentation solo ai set di train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5e79b9a",
   "metadata": {
    "executionInfo": {
     "elapsed": 29479,
     "status": "ok",
     "timestamp": 1747919645016,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "a5e79b9a"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, \"train\"), transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, \"valid\"), transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, \"test\"), transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Classi leggibili (opzionale)\n",
    "pretty_classes = ['Adenocarcinoma', 'Adgelcarcinoma', 'Squamosgelcarcinoma', 'Noncancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17cffb15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 835,
     "status": "ok",
     "timestamp": 1747919645840,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "17cffb15",
    "outputId": "5980fdd0-bdf6-46ab-e7f9-2c5f4de9edd9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/DAML/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/user/DAML/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet18(pretrained=True) # trasnfer learning\n",
    "\n",
    "# congela i layer convoluzionali per fare fine-tuning solo sull'ultimo layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Sblocca solo l'ultimo FC Layer\n",
    "num_features = model.fc.in_features # ultimo layer che mappa le classi\n",
    "model.fc = nn.Linear(num_features, 4)  # 4 classi\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220b0835",
   "metadata": {
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1747919645905,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "220b0835"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f0e828d",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1747919645917,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "2f0e828d"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "        scheduler.step()\n",
    "\n",
    "        # Valutazione\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "        val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95bbca79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1345164,
     "status": "ok",
     "timestamp": 1747921282412,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "95bbca79",
    "outputId": "1a130862-6815-48d6-8c2f-6b3dfefb5653"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/DAML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DAML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/DAML/.venv/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DAML/.venv/lib/python3.10/site-packages/torchvision/models/resnet.py:271\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m--> 271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n",
      "File \u001b[0;32m~/DAML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DAML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/DAML/.venv/lib/python3.10/site-packages/torch/nn/modules/pooling.py:213\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DAML/.venv/lib/python3.10/site-packages/torch/_jit_internal.py:622\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DAML/.venv/lib/python3.10/site-packages/torch/nn/functional.py:830\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 830\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7bd7a",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1747921282422,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "47f7bd7a"
   },
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, loader, class_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "    print(\"\\nDetailed per-class metrics:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196f86d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 583164,
     "status": "ok",
     "timestamp": 1747921865592,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "196f86d9",
    "outputId": "a8a0eb84-1769-42a3-ed64-4455e9e5131d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6159\n",
      "F1 Score : 0.6025\n",
      "Precision: 0.6801\n",
      "Recall   : 0.5977\n",
      "\n",
      "Detailed per-class metrics:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "     Adenocarcinoma       0.52      0.78      0.62       120\n",
      "     Adgelcarcinoma       0.65      0.22      0.32        51\n",
      "Squamosgelcarcinoma       1.00      1.00      1.00        54\n",
      "          Noncancer       0.55      0.40      0.46        90\n",
      "\n",
      "           accuracy                           0.62       315\n",
      "          macro avg       0.68      0.60      0.60       315\n",
      "       weighted avg       0.63      0.62      0.59       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_classes = ['Adenocarcinoma', 'Adgelcarcinoma', 'Squamosgelcarcinoma', 'Noncancer']\n",
    "evaluate_metrics(model, test_loader, pretty_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5QM7ybZvSucT",
   "metadata": {
    "id": "5QM7ybZvSucT"
   },
   "source": [
    " A me è uscito questo:\n",
    "\n",
    "Accuracy : 0.6095\n",
    "F1 Score : 0.5746\n",
    "Precision: 0.6418\n",
    "Recall   : 0.5815\n",
    "\n",
    "Detailed per-class metrics:\n",
    "                     precision    recall  f1-score   support\n",
    "\n",
    "     Adenocarcinoma       0.53      0.78      0.63       120\n",
    "     Adgelcarcinoma       0.50      0.12      0.19        51\n",
    "Squamosgelcarcinoma       1.00      1.00      1.00        54\n",
    "          Noncancer       0.54      0.43      0.48        90\n",
    "\n",
    "           accuracy                           0.61       315\n",
    "          macro avg       0.64      0.58      0.57       315\n",
    "       weighted avg       0.61      0.61      0.58       315\n",
    "\n",
    "Leggendo questi risultati sembra che vada tutto un po' così così perchè nonostante con 10 epoche l'accuracy sia al 61%, la recall è molto bassa e questo vuol dire che il modello fa difficoltà a trovare molti casi, specialmente per alcune classi in particolare.\n",
    "Analizzando i risulati per ogni classe si nota infatti come nessuna classe venga performi in maniera ottimale, sono tutte più o meno mediocri ad eccezione della seconda dove proprio non ci siamo e la terza che con tutto al massimo è alquanto sospetta (overfitting?).\n",
    "La seconda classe ha una recall molto bassa, vuol dire che non viene quasi mai riconosciuta.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5l_z-FRXV4Wp",
   "metadata": {
    "id": "5l_z-FRXV4Wp"
   },
   "source": [
    "Provo ad applicare data augmentation solo alle classi più piccole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JOwvkkmpUT2V",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1747921865642,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "JOwvkkmpUT2V"
   },
   "outputs": [],
   "source": [
    "#modifica ImageFolder per poter applicare DA diverse a seconda delle classi\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "class BalancedAugmentDataset(ImageFolder):\n",
    "    def __init__(self, root, transform_common=None, transform_augmented=None, classes_to_augment=None):\n",
    "        super().__init__(root, transform=None)\n",
    "        self.transform_common = transform_common\n",
    "        self.transform_augmented = transform_augmented\n",
    "        self.classes_to_augment = classes_to_augment or []\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, label = self.samples[index]\n",
    "        image = self.loader(path)\n",
    "\n",
    "        # Applica augmentation solo se la classe è tra quelle specificate\n",
    "        if self.classes[label] in self.classes_to_augment:\n",
    "            if self.transform_augmented:\n",
    "                image = self.transform_augmented(image)\n",
    "        else:\n",
    "            if self.transform_common:\n",
    "                image = self.transform_common(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2WhbJrxqV_eH",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1747921865647,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "2WhbJrxqV_eH"
   },
   "outputs": [],
   "source": [
    "# Trasformazione base (no augmentation)\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# Augmentation solo per le classi minoritarie\n",
    "augmented_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JpVku5eLWw9N",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747921865655,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "JpVku5eLWw9N"
   },
   "outputs": [],
   "source": [
    "# provo ad aumentare le classi 1 e 3\n",
    "classes_to_augment = [\"Adgelcarcinoma\", \"Noncancer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NmYCSNn2W1M6",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747921865668,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "NmYCSNn2W1M6"
   },
   "outputs": [],
   "source": [
    "# carica il training set con le nuove classi\n",
    "train_dataset = BalancedAugmentDataset(\n",
    "    root=os.path.join(dataset_path, \"train\"),\n",
    "    transform_common=base_transform,\n",
    "    transform_augmented=augmented_transform,\n",
    "    classes_to_augment=classes_to_augment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gqJq0SySXCsG",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1747921865685,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "gqJq0SySXCsG"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AbvJg_PeXO5B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 332014,
     "status": "ok",
     "timestamp": 1747922316953,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "AbvJg_PeXO5B",
    "outputId": "8d33b492-0b62-403d-d7d9-a0c3582d56fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 11.631 | Train Acc: 0.821 | Val Acc: 0.625\n",
      "Epoch 2/50 | Train Loss: 11.666 | Train Acc: 0.816 | Val Acc: 0.625\n",
      "Epoch 3/50 | Train Loss: 12.504 | Train Acc: 0.814 | Val Acc: 0.625\n",
      "Epoch 4/50 | Train Loss: 11.972 | Train Acc: 0.806 | Val Acc: 0.639\n",
      "Epoch 5/50 | Train Loss: 11.384 | Train Acc: 0.825 | Val Acc: 0.611\n",
      "Epoch 6/50 | Train Loss: 11.882 | Train Acc: 0.827 | Val Acc: 0.611\n",
      "Epoch 7/50 | Train Loss: 12.494 | Train Acc: 0.814 | Val Acc: 0.625\n",
      "Epoch 8/50 | Train Loss: 11.719 | Train Acc: 0.829 | Val Acc: 0.611\n",
      "Epoch 9/50 | Train Loss: 11.851 | Train Acc: 0.816 | Val Acc: 0.625\n",
      "Epoch 10/50 | Train Loss: 11.616 | Train Acc: 0.822 | Val Acc: 0.597\n",
      "Epoch 11/50 | Train Loss: 12.086 | Train Acc: 0.816 | Val Acc: 0.653\n",
      "Epoch 12/50 | Train Loss: 11.475 | Train Acc: 0.806 | Val Acc: 0.625\n",
      "Epoch 13/50 | Train Loss: 11.316 | Train Acc: 0.812 | Val Acc: 0.611\n",
      "Epoch 14/50 | Train Loss: 11.483 | Train Acc: 0.827 | Val Acc: 0.625\n",
      "Epoch 15/50 | Train Loss: 11.645 | Train Acc: 0.814 | Val Acc: 0.639\n",
      "Epoch 16/50 | Train Loss: 12.016 | Train Acc: 0.825 | Val Acc: 0.611\n",
      "Epoch 17/50 | Train Loss: 11.797 | Train Acc: 0.817 | Val Acc: 0.611\n",
      "Epoch 18/50 | Train Loss: 11.504 | Train Acc: 0.824 | Val Acc: 0.625\n",
      "Epoch 19/50 | Train Loss: 11.792 | Train Acc: 0.814 | Val Acc: 0.611\n",
      "Epoch 20/50 | Train Loss: 11.433 | Train Acc: 0.830 | Val Acc: 0.625\n",
      "Epoch 21/50 | Train Loss: 11.708 | Train Acc: 0.809 | Val Acc: 0.653\n",
      "Epoch 22/50 | Train Loss: 11.559 | Train Acc: 0.832 | Val Acc: 0.625\n",
      "Epoch 23/50 | Train Loss: 11.282 | Train Acc: 0.834 | Val Acc: 0.611\n",
      "Epoch 24/50 | Train Loss: 11.839 | Train Acc: 0.809 | Val Acc: 0.653\n",
      "Epoch 25/50 | Train Loss: 11.503 | Train Acc: 0.822 | Val Acc: 0.625\n",
      "Epoch 26/50 | Train Loss: 11.473 | Train Acc: 0.835 | Val Acc: 0.625\n",
      "Epoch 27/50 | Train Loss: 11.527 | Train Acc: 0.819 | Val Acc: 0.611\n",
      "Epoch 28/50 | Train Loss: 11.904 | Train Acc: 0.816 | Val Acc: 0.611\n",
      "Epoch 29/50 | Train Loss: 11.616 | Train Acc: 0.822 | Val Acc: 0.625\n",
      "Epoch 30/50 | Train Loss: 11.443 | Train Acc: 0.825 | Val Acc: 0.611\n",
      "Epoch 31/50 | Train Loss: 11.670 | Train Acc: 0.814 | Val Acc: 0.639\n",
      "Epoch 32/50 | Train Loss: 12.143 | Train Acc: 0.837 | Val Acc: 0.597\n",
      "Epoch 33/50 | Train Loss: 11.486 | Train Acc: 0.809 | Val Acc: 0.625\n",
      "Epoch 34/50 | Train Loss: 12.040 | Train Acc: 0.819 | Val Acc: 0.625\n",
      "Epoch 35/50 | Train Loss: 11.764 | Train Acc: 0.804 | Val Acc: 0.597\n",
      "Epoch 36/50 | Train Loss: 11.900 | Train Acc: 0.822 | Val Acc: 0.611\n",
      "Epoch 37/50 | Train Loss: 12.169 | Train Acc: 0.816 | Val Acc: 0.625\n",
      "Epoch 38/50 | Train Loss: 11.441 | Train Acc: 0.816 | Val Acc: 0.611\n",
      "Epoch 39/50 | Train Loss: 11.728 | Train Acc: 0.817 | Val Acc: 0.625\n",
      "Epoch 40/50 | Train Loss: 11.733 | Train Acc: 0.812 | Val Acc: 0.611\n",
      "Epoch 41/50 | Train Loss: 12.130 | Train Acc: 0.816 | Val Acc: 0.625\n",
      "Epoch 42/50 | Train Loss: 11.584 | Train Acc: 0.814 | Val Acc: 0.625\n",
      "Epoch 43/50 | Train Loss: 11.479 | Train Acc: 0.812 | Val Acc: 0.625\n",
      "Epoch 44/50 | Train Loss: 11.671 | Train Acc: 0.827 | Val Acc: 0.611\n",
      "Epoch 45/50 | Train Loss: 11.373 | Train Acc: 0.825 | Val Acc: 0.639\n",
      "Epoch 46/50 | Train Loss: 11.284 | Train Acc: 0.837 | Val Acc: 0.611\n",
      "Epoch 47/50 | Train Loss: 11.620 | Train Acc: 0.824 | Val Acc: 0.625\n",
      "Epoch 48/50 | Train Loss: 11.294 | Train Acc: 0.827 | Val Acc: 0.639\n",
      "Epoch 49/50 | Train Loss: 11.735 | Train Acc: 0.825 | Val Acc: 0.611\n",
      "Epoch 50/50 | Train Loss: 11.858 | Train Acc: 0.812 | Val Acc: 0.625\n"
     ]
    }
   ],
   "source": [
    "# riproviamo a trainare e valutare\n",
    "train_model(model, train_loader, val_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IG3DIR50Xog3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3058,
     "status": "ok",
     "timestamp": 1747922319959,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "IG3DIR50Xog3",
    "outputId": "19caecb6-7f6c-49be-a6be-608e060e97de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6444\n",
      "F1 Score : 0.6414\n",
      "Precision: 0.6947\n",
      "Recall   : 0.6307\n",
      "\n",
      "Detailed per-class metrics:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "     Adenocarcinoma       0.56      0.73      0.63       120\n",
      "     Adgelcarcinoma       0.64      0.27      0.38        51\n",
      "Squamosgelcarcinoma       1.00      0.98      0.99        54\n",
      "          Noncancer       0.59      0.53      0.56        90\n",
      "\n",
      "           accuracy                           0.64       315\n",
      "          macro avg       0.69      0.63      0.64       315\n",
      "       weighted avg       0.65      0.64      0.63       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_metrics(model, test_loader, pretty_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nyq66No8bpJ7",
   "metadata": {
    "id": "nyq66No8bpJ7"
   },
   "source": [
    "Ecco i risultati:\n",
    "Accuracy : 0.6667\n",
    "F1 Score : 0.6739\n",
    "Precision: 0.7011\n",
    "Recall   : 0.6647\n",
    "\n",
    "Detailed per-class metrics:\n",
    "                     precision    recall  f1-score   support\n",
    "\n",
    "     Adenocarcinoma       0.58      0.76      0.66       120\n",
    "     Adgelcarcinoma       0.58      0.41      0.48        51\n",
    "Squamosgelcarcinoma       1.00      1.00      1.00        54\n",
    "          Noncancer       0.64      0.49      0.55        90\n",
    "\n",
    "           accuracy                           0.67       315\n",
    "          macro avg       0.70      0.66      0.67       315\n",
    "       weighted avg       0.67      0.67      0.66       315\n",
    "\n",
    "Sostanzialmente un incremento dell'accuracy del 6% (adesso a 67%) e dell'F1 score di 10 punti (adesso a 0.67)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54Zb7dFGcSHt",
   "metadata": {
    "id": "54Zb7dFGcSHt"
   },
   "source": [
    "Provo ad usare una loss pesata sulle diverse classi in maniera tale da dare più peso agli errori delle classi più piccole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t-EiUh4QckLu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93,
     "status": "ok",
     "timestamp": 1747922325520,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "t-EiUh4QckLu",
    "outputId": "c08ae5dd-1e14-4798-b60e-a75b8c249f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [0.78589744 1.3326087  1.03547297 0.98870968]\n"
     ]
    }
   ],
   "source": [
    "# Estrai le etichette (interi) dal dataset di training\n",
    "labels = [label for _, label in train_dataset.samples]\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np # numpy is also needed for np.unique\n",
    "\n",
    "# Calcola i pesi bilanciati per ciascuna classe\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Converti in tensor e porta su device (CPU o GPU)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uXDpVZKRcrLD",
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1747922327532,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "uXDpVZKRcrLD"
   },
   "outputs": [],
   "source": [
    "# passo i pesi come parametro in maniera tale che durante il training gli errori sulle classi meno frequenti abbiano un peso maggiore e quindi il modello sarà incentivato a non \"ignorare\" quelle classi.\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R5cGJd-TnLoH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1747922328744,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "R5cGJd-TnLoH",
    "outputId": "c981f3a2-6fb2-4773-bd95-929898f4a32e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/DAML/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/user/DAML/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet18(pretrained=True) # trasnfer learning\n",
    "\n",
    "# congela i layer convoluzionali per fare fine-tuning solo sull'ultimo layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Sblocca solo l'ultimo FC Layer\n",
    "num_features = model.fc.in_features # ultimo layer che mappa le classi\n",
    "model.fc = nn.Linear(num_features, 4)  # 4 classi\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MejWpVy7dCEB",
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1747922330610,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "MejWpVy7dCEB"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "        scheduler.step()\n",
    "\n",
    "        # Valutazione\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "        val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6Fxt0PobdCla",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 329769,
     "status": "ok",
     "timestamp": 1747922671468,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "6Fxt0PobdCla",
    "outputId": "5dc8bd82-b22c-438f-8dd9-457487826c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 29.023 | Train Acc: 0.264 | Val Acc: 0.181\n",
      "Epoch 2/50 | Train Loss: 28.900 | Train Acc: 0.259 | Val Acc: 0.153\n",
      "Epoch 3/50 | Train Loss: 28.897 | Train Acc: 0.277 | Val Acc: 0.208\n",
      "Epoch 4/50 | Train Loss: 28.793 | Train Acc: 0.272 | Val Acc: 0.222\n",
      "Epoch 5/50 | Train Loss: 28.788 | Train Acc: 0.277 | Val Acc: 0.222\n",
      "Epoch 6/50 | Train Loss: 28.939 | Train Acc: 0.269 | Val Acc: 0.194\n",
      "Epoch 7/50 | Train Loss: 28.570 | Train Acc: 0.266 | Val Acc: 0.208\n",
      "Epoch 8/50 | Train Loss: 29.080 | Train Acc: 0.279 | Val Acc: 0.222\n",
      "Epoch 9/50 | Train Loss: 29.397 | Train Acc: 0.269 | Val Acc: 0.208\n",
      "Epoch 10/50 | Train Loss: 29.183 | Train Acc: 0.253 | Val Acc: 0.194\n",
      "Epoch 11/50 | Train Loss: 28.945 | Train Acc: 0.259 | Val Acc: 0.194\n",
      "Epoch 12/50 | Train Loss: 28.774 | Train Acc: 0.272 | Val Acc: 0.208\n",
      "Epoch 13/50 | Train Loss: 29.186 | Train Acc: 0.268 | Val Acc: 0.208\n",
      "Epoch 14/50 | Train Loss: 28.864 | Train Acc: 0.272 | Val Acc: 0.208\n",
      "Epoch 15/50 | Train Loss: 28.771 | Train Acc: 0.274 | Val Acc: 0.208\n",
      "Epoch 16/50 | Train Loss: 29.116 | Train Acc: 0.271 | Val Acc: 0.194\n",
      "Epoch 17/50 | Train Loss: 28.761 | Train Acc: 0.279 | Val Acc: 0.194\n",
      "Epoch 18/50 | Train Loss: 28.753 | Train Acc: 0.292 | Val Acc: 0.236\n",
      "Epoch 19/50 | Train Loss: 29.322 | Train Acc: 0.274 | Val Acc: 0.208\n",
      "Epoch 20/50 | Train Loss: 28.919 | Train Acc: 0.274 | Val Acc: 0.222\n",
      "Epoch 21/50 | Train Loss: 28.603 | Train Acc: 0.269 | Val Acc: 0.208\n",
      "Epoch 22/50 | Train Loss: 28.850 | Train Acc: 0.271 | Val Acc: 0.194\n",
      "Epoch 23/50 | Train Loss: 29.142 | Train Acc: 0.266 | Val Acc: 0.208\n",
      "Epoch 24/50 | Train Loss: 28.639 | Train Acc: 0.271 | Val Acc: 0.194\n",
      "Epoch 25/50 | Train Loss: 28.771 | Train Acc: 0.268 | Val Acc: 0.194\n",
      "Epoch 26/50 | Train Loss: 28.991 | Train Acc: 0.269 | Val Acc: 0.222\n",
      "Epoch 27/50 | Train Loss: 28.912 | Train Acc: 0.269 | Val Acc: 0.208\n",
      "Epoch 28/50 | Train Loss: 28.804 | Train Acc: 0.279 | Val Acc: 0.194\n",
      "Epoch 29/50 | Train Loss: 28.720 | Train Acc: 0.268 | Val Acc: 0.194\n",
      "Epoch 30/50 | Train Loss: 28.585 | Train Acc: 0.271 | Val Acc: 0.236\n",
      "Epoch 31/50 | Train Loss: 29.211 | Train Acc: 0.274 | Val Acc: 0.194\n",
      "Epoch 32/50 | Train Loss: 28.759 | Train Acc: 0.272 | Val Acc: 0.194\n",
      "Epoch 33/50 | Train Loss: 28.842 | Train Acc: 0.266 | Val Acc: 0.194\n",
      "Epoch 34/50 | Train Loss: 29.066 | Train Acc: 0.277 | Val Acc: 0.222\n",
      "Epoch 35/50 | Train Loss: 28.666 | Train Acc: 0.271 | Val Acc: 0.194\n",
      "Epoch 36/50 | Train Loss: 28.946 | Train Acc: 0.277 | Val Acc: 0.208\n",
      "Epoch 37/50 | Train Loss: 28.443 | Train Acc: 0.277 | Val Acc: 0.194\n",
      "Epoch 38/50 | Train Loss: 28.451 | Train Acc: 0.279 | Val Acc: 0.222\n",
      "Epoch 39/50 | Train Loss: 28.844 | Train Acc: 0.268 | Val Acc: 0.236\n",
      "Epoch 40/50 | Train Loss: 28.490 | Train Acc: 0.271 | Val Acc: 0.194\n",
      "Epoch 41/50 | Train Loss: 28.976 | Train Acc: 0.276 | Val Acc: 0.194\n",
      "Epoch 42/50 | Train Loss: 28.604 | Train Acc: 0.268 | Val Acc: 0.250\n",
      "Epoch 43/50 | Train Loss: 29.257 | Train Acc: 0.274 | Val Acc: 0.194\n",
      "Epoch 44/50 | Train Loss: 28.647 | Train Acc: 0.266 | Val Acc: 0.194\n",
      "Epoch 45/50 | Train Loss: 28.901 | Train Acc: 0.266 | Val Acc: 0.194\n",
      "Epoch 46/50 | Train Loss: 28.988 | Train Acc: 0.263 | Val Acc: 0.208\n",
      "Epoch 47/50 | Train Loss: 28.976 | Train Acc: 0.259 | Val Acc: 0.208\n",
      "Epoch 48/50 | Train Loss: 28.735 | Train Acc: 0.271 | Val Acc: 0.222\n",
      "Epoch 49/50 | Train Loss: 29.067 | Train Acc: 0.254 | Val Acc: 0.194\n",
      "Epoch 50/50 | Train Loss: 28.687 | Train Acc: 0.263 | Val Acc: 0.208\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dSDd0PX-fFh2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3097,
     "status": "ok",
     "timestamp": 1747922674608,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "dSDd0PX-fFh2",
    "outputId": "102eda6e-aa4f-4c83-ab15-8e1e250a070e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.2444\n",
      "F1 Score : 0.1958\n",
      "Precision: 0.3170\n",
      "Recall   : 0.3570\n",
      "\n",
      "Detailed per-class metrics:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "     Adenocarcinoma       0.00      0.00      0.00       120\n",
      "     Adgelcarcinoma       0.20      0.57      0.30        51\n",
      "Squamosgelcarcinoma       0.27      0.81      0.40        54\n",
      "          Noncancer       0.80      0.04      0.08        90\n",
      "\n",
      "           accuracy                           0.24       315\n",
      "          macro avg       0.32      0.36      0.20       315\n",
      "       weighted avg       0.31      0.24      0.14       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_classes = ['Adenocarcinoma', 'Adgelcarcinoma', 'Squamosgelcarcinoma', 'Noncancer']\n",
    "evaluate_metrics(model, test_loader, pretty_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FYJLpNYqjPjv",
   "metadata": {
    "id": "FYJLpNYqjPjv"
   },
   "source": [
    "ho ottenuto:\n",
    "\n",
    "Accuracy : 0.6889\n",
    "F1 Score : 0.7054\n",
    "Precision: 0.7114\n",
    "Recall   : 0.7017\n",
    "\n",
    "Detailed per-class metrics:\n",
    "                     precision    recall  f1-score   support\n",
    "\n",
    "     Adenocarcinoma       0.64      0.65      0.64       120\n",
    "     Adgelcarcinoma       0.58      0.49      0.53        51\n",
    "Squamosgelcarcinoma       1.00      1.00      1.00        54\n",
    "          Noncancer       0.62      0.67      0.65        90\n",
    "\n",
    "           accuracy                           0.69       315\n",
    "          macro avg       0.71      0.70      0.71       315\n",
    "       weighted avg       0.69      0.69      0.69       315\n",
    "\n",
    "Rispetto al primissiomo training la sitauzione è migliorata di molto in quanto:\n",
    "Accuracy da 60% a 69%, F1 score da 0.57 a 0.71, Precision da 0.64 a 0.71,Recall da 0.58 a 0.70, la classe più piccola (Adgelcarcinoma) è passata da un F1 score di 0.19 a uno di 0.53!\n",
    "Dajee!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B-4tygGmoLpP",
   "metadata": {
    "id": "B-4tygGmoLpP"
   },
   "source": [
    "Provo a fare dropout sull'ultimo layer e aggiungo l'early stopping durante il training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7SRCmikcOx",
   "metadata": {
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1747916091081,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "7b7SRCmikcOx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/DAML/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/user/DAML/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet18(pretrained=True) # trasnfer learning\n",
    "\n",
    "# congela i layer convoluzionali per fare fine-tuning solo sull'ultimo layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# dropout\n",
    "import torch.nn as nn\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(num_features, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ECNG3q3DiNs",
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1747916093383,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "6ECNG3q3DiNs"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=50, patience=5):\n",
    "    best_val_loss = float('inf') # inizializzo la loss migliore a infinito\n",
    "    epochs_without_improvement = 0 # conta quante epoche senza migliorare\n",
    "    best_model_state = None #per salvare i pesi del modello migliore\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader: #training\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "        scheduler.step() #aggiorna il learning rate\n",
    "\n",
    "        # Validazione\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc:.3f} | Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f}\")\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            best_model_state = model.state_dict()  # salva il miglior modello\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"  [EarlyStopping] No improvement for {epochs_without_improvement} epoch(s)\")\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Early stopping triggered. Restoring best model weights.\")\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nb0ll7PC8dql",
   "metadata": {
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1747916560467,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "Nb0ll7PC8dql"
   },
   "outputs": [],
   "source": [
    "model = model.to(device) # per farlo lavorare su GPU o CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4IoolK2qoEZM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "executionInfo": {
     "elapsed": 54194,
     "status": "error",
     "timestamp": 1747918949598,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "4IoolK2qoEZM",
    "outputId": "9437cdf8-13e4-40a7-f429-77bd704721ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 | Train Loss: 32.496 | Train Acc: 0.285 | Val Loss: 4.346 | Val Acc: 0.278\n",
      "Epoch 2/40 | Train Loss: 32.185 | Train Acc: 0.290 | Val Loss: 4.113 | Val Acc: 0.319\n",
      "Epoch 3/40 | Train Loss: 32.031 | Train Acc: 0.284 | Val Loss: 4.053 | Val Acc: 0.319\n",
      "Epoch 4/40 | Train Loss: 32.022 | Train Acc: 0.263 | Val Loss: 4.207 | Val Acc: 0.333\n",
      "  [EarlyStopping] No improvement for 1 epoch(s)\n",
      "Epoch 5/40 | Train Loss: 31.314 | Train Acc: 0.284 | Val Loss: 4.382 | Val Acc: 0.333\n",
      "  [EarlyStopping] No improvement for 2 epoch(s)\n",
      "Epoch 6/40 | Train Loss: 32.786 | Train Acc: 0.232 | Val Loss: 4.387 | Val Acc: 0.347\n",
      "  [EarlyStopping] No improvement for 3 epoch(s)\n",
      "Epoch 7/40 | Train Loss: 32.051 | Train Acc: 0.279 | Val Loss: 4.402 | Val Acc: 0.306\n",
      "  [EarlyStopping] No improvement for 4 epoch(s)\n",
      "Epoch 8/40 | Train Loss: 32.590 | Train Acc: 0.276 | Val Loss: 4.384 | Val Acc: 0.361\n",
      "  [EarlyStopping] No improvement for 5 epoch(s)\n",
      "Early stopping triggered. Restoring best model weights.\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, epochs=40, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bMuEl9pjENuv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "executionInfo": {
     "elapsed": 390929,
     "status": "error",
     "timestamp": 1747918879163,
     "user": {
      "displayName": "Mirko D'Auria",
      "userId": "08943305403859940658"
     },
     "user_tz": -120
    },
    "id": "bMuEl9pjENuv",
    "outputId": "28e8daa3-0cf1-4af9-d4aa-131b18de5589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.4032\n",
      "F1 Score : 0.2435\n",
      "Precision: 0.3377\n",
      "Recall   : 0.2919\n",
      "\n",
      "Detailed per-class metrics:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "     Adenocarcinoma       0.42      0.91      0.58       120\n",
      "     Adgelcarcinoma       0.00      0.00      0.00        51\n",
      "Squamosgelcarcinoma       0.67      0.15      0.24        54\n",
      "          Noncancer       0.26      0.11      0.16        90\n",
      "\n",
      "           accuracy                           0.40       315\n",
      "          macro avg       0.34      0.29      0.24       315\n",
      "       weighted avg       0.35      0.40      0.31       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_classes = ['Adenocarcinoma', 'Adgelcarcinoma', 'Squamosgelcarcinoma', 'Noncancer']\n",
    "evaluate_metrics(model, test_loader, pretty_classes)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
