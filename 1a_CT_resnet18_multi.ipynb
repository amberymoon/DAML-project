{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e60bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be4b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d53e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(base_dir, 'data_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4e1097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean e std per immagini RGB normalizzate su [-1, 1]\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# per fare data augmentation utiliziammo transforms.Compose di torchvision, facciamo data augmentation solo ai set di train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5e79b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, \"train\"), transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, \"valid\"), transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(dataset_path, \"test\"), transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Classi leggibili (opzionale)\n",
    "pretty_classes = ['Adenocarcinoma', 'Adgelcarcinoma', 'Squamosgelcarcinoma', 'Noncancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cffb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noemi\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\noemi\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\noemi/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:11<00:00, 3.92MB/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet18(pretrained=True) # trasnfer learning\n",
    "\n",
    "# congela i layer convoluzionali per fare fine-tuning solo sull'ultimo layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Sblocca solo l'ultimo FC Layer\n",
    "num_features = model.fc.in_features # ultimo layer che mappa le classi\n",
    "model.fc = nn.Linear(num_features, 4)  # 4 classi\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f0e828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "        scheduler.step()\n",
    "\n",
    "        # Valutazione\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "        val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95bbca79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 25.605 | Train Acc: 0.423 | Val Acc: 0.375\n",
      "Epoch 2/10 | Train Loss: 20.885 | Train Acc: 0.574 | Val Acc: 0.417\n",
      "Epoch 3/10 | Train Loss: 18.333 | Train Acc: 0.630 | Val Acc: 0.431\n",
      "Epoch 4/10 | Train Loss: 16.790 | Train Acc: 0.659 | Val Acc: 0.486\n",
      "Epoch 5/10 | Train Loss: 16.184 | Train Acc: 0.682 | Val Acc: 0.556\n",
      "Epoch 6/10 | Train Loss: 14.900 | Train Acc: 0.726 | Val Acc: 0.472\n",
      "Epoch 7/10 | Train Loss: 14.450 | Train Acc: 0.715 | Val Acc: 0.597\n",
      "Epoch 8/10 | Train Loss: 14.665 | Train Acc: 0.729 | Val Acc: 0.486\n",
      "Epoch 9/10 | Train Loss: 14.809 | Train Acc: 0.698 | Val Acc: 0.583\n",
      "Epoch 10/10 | Train Loss: 14.703 | Train Acc: 0.726 | Val Acc: 0.569\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, loader, class_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "    print(\"\\nDetailed per-class metrics:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "196f86d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6095\n",
      "F1 Score : 0.5749\n",
      "Precision: 0.6825\n",
      "Recall   : 0.5783\n",
      "\n",
      "Detailed per-class metrics:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "     Adenocarcinoma       0.52      0.84      0.64       120\n",
      "     Adgelcarcinoma       0.67      0.16      0.25        51\n",
      "Squamosgelcarcinoma       1.00      0.98      0.99        54\n",
      "          Noncancer       0.55      0.33      0.41        90\n",
      "\n",
      "           accuracy                           0.61       315\n",
      "          macro avg       0.68      0.58      0.57       315\n",
      "       weighted avg       0.63      0.61      0.57       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_classes = ['Adenocarcinoma', 'Adgelcarcinoma', 'Squamosgelcarcinoma', 'Noncancer']\n",
    "evaluate_metrics(model, test_loader, pretty_classes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
